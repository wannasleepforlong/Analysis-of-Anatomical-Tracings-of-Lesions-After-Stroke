{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam,Nadam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, TensorBoard\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers import Input, BatchNormalization, Dropout, PReLU, add, concatenate\n",
    "from keras.models import Model\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from utils import get_score_from_all_slices\n",
    "from model import create_xception_unet_n\n",
    "from loss import  dice, dice_loss, get_loss\n",
    "from data import create_train_date_generator, create_val_date_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dice_coef(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true),axis=-1) + K.sum(K.square(y_pred),axis=-1) + epsilon)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resBlock(conv,stage,keep_prob,stage_num=5):\n",
    "    \n",
    "    inputs=conv\n",
    "    \n",
    "    for _ in range(3 if stage>3 else stage):\n",
    "        conv=PReLU()(BatchNormalization()(Conv2D(16*(2**(stage-1)), 5, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv)))\n",
    "    conv_add=PReLU()(add([inputs,conv]))\n",
    "    conv_drop=Dropout(keep_prob)(conv_add)\n",
    "    \n",
    "    if stage<stage_num:\n",
    "        conv_downsample=PReLU()(BatchNormalization()(Conv2D(16*(2**stage), 2, strides=(2, 2),activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv_drop)))\n",
    "        return conv_downsample,conv_add\n",
    "    else:\n",
    "        return conv_add,conv_add\n",
    "    \n",
    "    \n",
    "def up_resBlock(forward_conv,input_conv,stage):\n",
    "    conv=concatenate([forward_conv,input_conv],axis = -1)\n",
    "    print('conv_concatenate:',conv.get_shape().as_list())\n",
    "    for _ in range(3 if stage>3 else stage):\n",
    "        conv=PReLU()(BatchNormalization()(Conv2D(16*(2**(stage-1)), 5, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv)))\n",
    "        print('conv_up_stage_%d:' %stage,conv.get_shape().as_list())\n",
    "    conv_add=PReLU()(add([input_conv,conv]))\n",
    "    if stage>1:\n",
    "        conv_upsample=PReLU()(BatchNormalization()(Conv2DTranspose(16*(2**(stage-2)),2,strides=(2, 2),padding='valid',activation = None,kernel_initializer = 'he_normal')(conv_add)))\n",
    "        return conv_upsample\n",
    "    else:\n",
    "        return conv_add\n",
    "\n",
    "def vnet(pretrained_weights = None,input_size = (192,192,4),num_class=1,is_training=True,stage_num=5,thresh=0.5):\n",
    "    keep_prob = 0.1\n",
    "    features=[]\n",
    "    input_model = Input(input_size)\n",
    "    x=PReLU()(BatchNormalization()(Conv2D(16, 5, activation = None, padding = 'same', kernel_initializer = 'he_normal')(input_model)))\n",
    "    \n",
    "    for s in range(1,stage_num+1):\n",
    "        x,feature=resBlock(x,s,keep_prob)\n",
    "        features.append(feature)\n",
    "        \n",
    "    conv_up=PReLU()(BatchNormalization()(Conv2DTranspose(16*(2**(s-2)),2,strides=(2, 2),padding='valid',activation = None,kernel_initializer = 'he_normal')(x)))\n",
    "    \n",
    "    for d in range(stage_num-1,0,-1):\n",
    "        conv_up=up_resBlock(features[d-1],conv_up,d)\n",
    "    if num_class>1:\n",
    "        conv_out=Conv2D(num_class, 1, activation = 'softmax', padding = 'same', kernel_initializer = 'he_normal')(conv_up)\n",
    "    else:\n",
    "        conv_out=Conv2D(num_class, 1, activation = 'sigmoid', padding = 'same', kernel_initializer = 'he_normal')(conv_up)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model=Model(inputs=input_model,outputs=conv_out)    \n",
    "\n",
    "    return model\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_file_path = '/data/data/ATLAS_h5/ATLAS.h5'\n",
    "# data_file_path = r\"C:\\Users\\HP\\X-Net\\data\\train66.h5\"\n",
    "data_file_path = 'Data/Atlas_R2.0/Atlas_2/train66.h5'\n",
    "pretrained_weights_file = None\n",
    "input_shape = (224, 192, 1)\n",
    "batch_size = 8\n",
    "num_folds = 5\n",
    "\n",
    "\n",
    "def train(fold, train_patient_indexes, val_patient_indexes):\n",
    "\n",
    "    log_dir = 'fold_' + str(fold) + '/'\n",
    "    if not os.path.isdir(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "    num_slices_train = len(train_patient_indexes) * 189\n",
    "    num_slices_val = len(val_patient_indexes) * 189\n",
    "\n",
    "    # Create model\n",
    "    K.clear_session()\n",
    "    model = vnet(input_size=input_shape)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss=get_loss, metrics=[dice])\n",
    "\n",
    "    # Get callbacks\n",
    "    #checkpoint = ModelCheckpoint(log_dir + 'ep={epoch:03d}-loss={loss:.3f}-val_loss={val_loss:.3f}.h5', verbose=1,\n",
    "    #                             monitor='val_loss', save_weights_only=True, save_best_only=True, save_freq=1)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep={epoch:03d}-loss={loss:.3f}.h5', verbose=1,\n",
    "                             monitor='loss', save_weights_only=True, save_best_only=True, save_freq=1)\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, min_delta=1e-3, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)\n",
    "    csv_logger = CSVLogger(log_dir + 'record.csv')\n",
    "    tensorboard = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    # train the model\n",
    "    model.fit(\n",
    "        create_train_date_generator(patient_indexes=train_patient_indexes, h5_file_path=data_file_path, batch_size=batch_size),\n",
    "        steps_per_epoch=max(1, num_slices_train // batch_size),\n",
    "        validation_data=create_val_date_generator(patient_indexes=val_patient_indexes, h5_file_path=data_file_path, batch_size=9),\n",
    "        validation_steps=max(1, num_slices_val // 9),\n",
    "        epochs=1,    #100\n",
    "        initial_epoch=0,\n",
    "        callbacks=[checkpoint, reduce_lr, early_stopping, tensorboard, csv_logger])\n",
    "    model.save_weights(log_dir + 'trained_final_weights.h5')\n",
    "\n",
    "    # Evaluate model\n",
    "    predicts = []\n",
    "    labels = []\n",
    "    f = create_val_date_generator(patient_indexes=val_patient_indexes, h5_file_path=data_file_path)\n",
    "    for _ in range(num_slices_val):\n",
    "        img, label = f.__next__()\n",
    "        predicts.append(model.predict(img))\n",
    "        labels.append(label)\n",
    "    predicts = np.array(predicts)\n",
    "    labels = np.array(labels)\n",
    "    score_record = get_score_from_all_slices(labels=labels, predicts=predicts)\n",
    "\n",
    "    # save score\n",
    "    df = pd.DataFrame(score_record)\n",
    "    df.to_csv(os.path.join(log_dir, 'score_record.csv'), index=False)\n",
    "\n",
    "    # print score\n",
    "    mean_score = {}\n",
    "    for key in score_record.keys():\n",
    "        print('In fold ', fold, ', average', key, ' value is: \\t ', np.mean(score_record[key]))\n",
    "        mean_score[key] = np.mean(score_record[key])\n",
    "\n",
    "    # exit training\n",
    "    K.clear_session()\n",
    "    return mean_score\n",
    "\n",
    "\n",
    "def main():\n",
    "    # prepare indexes of patients for training and validation, respectively\n",
    "    num_patients = 66  #229\n",
    "    patients_indexes = np.array([i for i in range(num_patients)])\n",
    "    kf = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "    # train, and record the scores of each fold\n",
    "    folds_score = []\n",
    "    for fold, (train_patient_indexes, val_patient_indexes) in enumerate(kf.split(patients_indexes)):\n",
    "        fold_mean_score = train(fold=fold, train_patient_indexes=train_patient_indexes, val_patient_indexes=val_patient_indexes)\n",
    "        folds_score.append(fold_mean_score)\n",
    "\n",
    "    # calculate average score\n",
    "    print('Final score from ', num_folds, ' folds cross validation:')\n",
    "    final_score = {}\n",
    "    for key in folds_score[0].keys():\n",
    "        scores = []\n",
    "        for i in range(num_folds):\n",
    "            scores.append(folds_score[i][key])\n",
    "        final_score[key] = np.mean(scores)\n",
    "        print(key, ' score: \\t', final_score[key])\n",
    "\n",
    "    # save final score\n",
    "    df = pd.DataFrame(final_score, index=[0])\n",
    "    df.to_csv('x_net_final_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_concatenate: [None, 28, 24, 256]\n",
      "conv_up_stage_4: [None, 28, 24, 128]\n",
      "conv_up_stage_4: [None, 28, 24, 128]\n",
      "conv_up_stage_4: [None, 28, 24, 128]\n",
      "conv_concatenate: [None, 56, 48, 128]\n",
      "conv_up_stage_3: [None, 56, 48, 64]\n",
      "conv_up_stage_3: [None, 56, 48, 64]\n",
      "conv_up_stage_3: [None, 56, 48, 64]\n",
      "conv_concatenate: [None, 112, 96, 64]\n",
      "conv_up_stage_2: [None, 112, 96, 32]\n",
      "conv_up_stage_2: [None, 112, 96, 32]\n",
      "conv_concatenate: [None, 224, 192, 32]\n",
      "conv_up_stage_1: [None, 224, 192, 16]\n",
      "9828\n",
      "\n",
      "Epoch 1: loss improved from inf to 2.95194, saving model to fold_0\\ep=001-loss=2.952.h5\n",
      "   1/1228 [..............................] - ETA: 2:42:47 - loss: 2.9519 - dice: 0.0044\n",
      "Epoch 1: loss improved from 2.95194 to 2.77991, saving model to fold_0\\ep=001-loss=2.780.h5\n",
      "   2/1228 [..............................] - ETA: 45:09 - loss: 2.7799 - dice: 0.0081  \n",
      "Epoch 1: loss improved from 2.77991 to 2.64711, saving model to fold_0\\ep=001-loss=2.647.h5\n",
      "   3/1228 [..............................] - ETA: 1:11:37 - loss: 2.6471 - dice: 0.0056\n",
      "Epoch 1: loss improved from 2.64711 to 2.53876, saving model to fold_0\\ep=001-loss=2.539.h5\n",
      "   4/1228 [..............................] - ETA: 1:02:37 - loss: 2.5388 - dice: 0.0092\n",
      "Epoch 1: loss improved from 2.53876 to 2.46409, saving model to fold_0\\ep=001-loss=2.464.h5\n",
      "   5/1228 [..............................] - ETA: 59:41 - loss: 2.4641 - dice: 0.0078  \n",
      "Epoch 1: loss improved from 2.46409 to 2.38887, saving model to fold_0\\ep=001-loss=2.389.h5\n",
      "   6/1228 [..............................] - ETA: 59:07 - loss: 2.3889 - dice: 0.0091\n",
      "Epoch 1: loss improved from 2.38887 to 2.34325, saving model to fold_0\\ep=001-loss=2.343.h5\n",
      "   7/1228 [..............................] - ETA: 58:34 - loss: 2.3433 - dice: 0.0081\n",
      "Epoch 1: loss improved from 2.34325 to 2.29290, saving model to fold_0\\ep=001-loss=2.293.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      2\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m folds_score \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_patient_indexes, val_patient_indexes) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(patients_indexes)):\n\u001b[1;32m---> 81\u001b[0m     fold_mean_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_patient_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_patient_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_patient_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_patient_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     folds_score\u001b[38;5;241m.\u001b[39mappend(fold_mean_score)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# calculate average score\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(fold, train_patient_indexes, val_patient_indexes)\u001b[0m\n\u001b[0;32m     32\u001b[0m tensorboard \u001b[38;5;241m=\u001b[39m TensorBoard(log_dir\u001b[38;5;241m=\u001b[39mlog_dir)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_train_date_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_patient_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_slices_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_val_date_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_patient_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_slices_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#100\u001b[39;49;00m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39msave_weights(log_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_final_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:1454\u001b[0m, in \u001b[0;36mModelCheckpoint.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_save_on_batch(batch):\n\u001b[1;32m-> 1454\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_current_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:1522\u001b[0m, in \u001b[0;36mModelCheckpoint._save_model\u001b[1;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest \u001b[38;5;241m=\u001b[39m current\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_weights_only:\n\u001b[1;32m-> 1522\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1528\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave(\n\u001b[0;32m   1529\u001b[0m         filepath,\n\u001b[0;32m   1530\u001b[0m         overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1531\u001b[0m         options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options,\n\u001b[0;32m   1532\u001b[0m     )\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py:2815\u001b[0m, in \u001b[0;36mModel.save_weights\u001b[1;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[0;32m   2813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2814\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m-> 2815\u001b[0m         \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights_to_hdf5_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m   2818\u001b[0m         \u001b[38;5;66;03m# Call `get_session` to initialize any uninitialized variables.\u001b[39;00m\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\saving\\hdf5_format.py:755\u001b[0m, in \u001b[0;36msave_weights_to_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    753\u001b[0m     g \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mcreate_group(layer\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    754\u001b[0m     weights \u001b[38;5;241m=\u001b[39m _legacy_weights(layer)\n\u001b[1;32m--> 755\u001b[0m     \u001b[43msave_subset_weights_to_hdf5_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    756\u001b[0m weights \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_trainable_weights \u001b[38;5;241m+\u001b[39m model\u001b[38;5;241m.\u001b[39m_non_trainable_weights\n\u001b[0;32m    757\u001b[0m g \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mcreate_group(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_level_model_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\keras\\saving\\hdf5_format.py:732\u001b[0m, in \u001b[0;36msave_subset_weights_to_hdf5_group\u001b[1;34m(f, weights)\u001b[0m\n\u001b[0;32m    730\u001b[0m     param_dset[()] \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m     param_dset[:] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\ExtInstallations\\OtherApps\\Anaconda\\lib\\site-packages\\h5py\\_hl\\dataset.py:982\u001b[0m, in \u001b[0;36mDataset.__setitem__\u001b[1;34m(self, args, val)\u001b[0m\n\u001b[0;32m    980\u001b[0m mspace \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(selection\u001b[38;5;241m.\u001b[39mexpand_shape(mshape))\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fspace \u001b[38;5;129;01min\u001b[39;00m selection\u001b[38;5;241m.\u001b[39mbroadcast(mshape):\n\u001b[1;32m--> 982\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
